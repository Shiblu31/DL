{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shiblu31/DL/blob/main/LSTM_02_cmpsx.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "W035C-igXyJa"
      },
      "outputs": [],
      "source": [
        "faqs = \"\"\"About Shiblu\n",
        "What is Shiblu's full name ??\n",
        "Shiblu's full name is Mrithunjoy Das (Shiblu)\n",
        "\n",
        "What is Shiblu's mother name ?\n",
        "Shiblu's name is Lucky Rani Das.\n",
        "\n",
        "How many sibilings Shiblu has ??\n",
        "Shiblu has 6 Sibilings.\n",
        "\n",
        "How many brother and sister  Shiblu has ?\n",
        "Shiblu has 4 brother and 2 sister. name of his twin brother is Soumya and Soumitra . twin sister name is Soumi and Srija.\n",
        "\n",
        "Shiblu school name is Sitakund Govt. model high school. Shiblu college name is Chittagong Cant. public college. Shiblu University name is\n",
        "Comilla University . Shiblu department name is Computer Science & Engineering. Shiblu dream job is MLOPs engineer.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "i6_Xy20qbpq-"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()"
      ],
      "metadata": {
        "id": "yuh9dIamHOPE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts([faqs])"
      ],
      "metadata": {
        "id": "kFeHJkjJHUCj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3AbXR3pHXkT",
        "outputId": "c847801a-cd28-4856-b21c-a88e9f1c0d33"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'shiblu': 1,\n",
              " 'is': 2,\n",
              " 'name': 3,\n",
              " \"shiblu's\": 4,\n",
              " 'has': 5,\n",
              " 'and': 6,\n",
              " 'brother': 7,\n",
              " 'sister': 8,\n",
              " 'what': 9,\n",
              " 'full': 10,\n",
              " 'das': 11,\n",
              " 'how': 12,\n",
              " 'many': 13,\n",
              " 'sibilings': 14,\n",
              " 'twin': 15,\n",
              " 'school': 16,\n",
              " 'college': 17,\n",
              " 'university': 18,\n",
              " 'about': 19,\n",
              " 'mrithunjoy': 20,\n",
              " 'mother': 21,\n",
              " 'lucky': 22,\n",
              " 'rani': 23,\n",
              " '6': 24,\n",
              " '4': 25,\n",
              " '2': 26,\n",
              " 'of': 27,\n",
              " 'his': 28,\n",
              " 'soumya': 29,\n",
              " 'soumitra': 30,\n",
              " 'soumi': 31,\n",
              " 'srija': 32,\n",
              " 'sitakund': 33,\n",
              " 'govt': 34,\n",
              " 'model': 35,\n",
              " 'high': 36,\n",
              " 'chittagong': 37,\n",
              " 'cant': 38,\n",
              " 'public': 39,\n",
              " 'comilla': 40,\n",
              " 'department': 41,\n",
              " 'computer': 42,\n",
              " 'science': 43,\n",
              " 'engineering': 44,\n",
              " 'dream': 45,\n",
              " 'job': 46,\n",
              " 'mlops': 47,\n",
              " 'engineer': 48}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = []\n",
        "for sentence in faqs.split('\\n'):\n",
        "  tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0]\n",
        "\n",
        "  for i in range(1,len(tokenized_sentence)):\n",
        "    input_sequences.append(tokenized_sentence[:i+1])\n"
      ],
      "metadata": {
        "id": "iY5kINLuISYW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEFkUMVYI-1F",
        "outputId": "1db37755-b22c-4014-c5c6-378dd0c48578"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[19, 1],\n",
              " [9, 2],\n",
              " [9, 2, 4],\n",
              " [9, 2, 4, 10],\n",
              " [9, 2, 4, 10, 3],\n",
              " [4, 10],\n",
              " [4, 10, 3],\n",
              " [4, 10, 3, 2],\n",
              " [4, 10, 3, 2, 20],\n",
              " [4, 10, 3, 2, 20, 11],\n",
              " [4, 10, 3, 2, 20, 11, 1],\n",
              " [9, 2],\n",
              " [9, 2, 4],\n",
              " [9, 2, 4, 21],\n",
              " [9, 2, 4, 21, 3],\n",
              " [4, 3],\n",
              " [4, 3, 2],\n",
              " [4, 3, 2, 22],\n",
              " [4, 3, 2, 22, 23],\n",
              " [4, 3, 2, 22, 23, 11],\n",
              " [12, 13],\n",
              " [12, 13, 14],\n",
              " [12, 13, 14, 1],\n",
              " [12, 13, 14, 1, 5],\n",
              " [1, 5],\n",
              " [1, 5, 24],\n",
              " [1, 5, 24, 14],\n",
              " [12, 13],\n",
              " [12, 13, 7],\n",
              " [12, 13, 7, 6],\n",
              " [12, 13, 7, 6, 8],\n",
              " [12, 13, 7, 6, 8, 1],\n",
              " [12, 13, 7, 6, 8, 1, 5],\n",
              " [1, 5],\n",
              " [1, 5, 25],\n",
              " [1, 5, 25, 7],\n",
              " [1, 5, 25, 7, 6],\n",
              " [1, 5, 25, 7, 6, 26],\n",
              " [1, 5, 25, 7, 6, 26, 8],\n",
              " [1, 5, 25, 7, 6, 26, 8, 3],\n",
              " [1, 5, 25, 7, 6, 26, 8, 3, 27],\n",
              " [1, 5, 25, 7, 6, 26, 8, 3, 27, 28],\n",
              " [1, 5, 25, 7, 6, 26, 8, 3, 27, 28, 15],\n",
              " [1, 5, 25, 7, 6, 26, 8, 3, 27, 28, 15, 7],\n",
              " [1, 5, 25, 7, 6, 26, 8, 3, 27, 28, 15, 7, 2],\n",
              " [1, 5, 25, 7, 6, 26, 8, 3, 27, 28, 15, 7, 2, 29],\n",
              " [1, 5, 25, 7, 6, 26, 8, 3, 27, 28, 15, 7, 2, 29, 6],\n",
              " [1, 5, 25, 7, 6, 26, 8, 3, 27, 28, 15, 7, 2, 29, 6, 30],\n",
              " [1, 5, 25, 7, 6, 26, 8, 3, 27, 28, 15, 7, 2, 29, 6, 30, 15],\n",
              " [1, 5, 25, 7, 6, 26, 8, 3, 27, 28, 15, 7, 2, 29, 6, 30, 15, 8],\n",
              " [1, 5, 25, 7, 6, 26, 8, 3, 27, 28, 15, 7, 2, 29, 6, 30, 15, 8, 3],\n",
              " [1, 5, 25, 7, 6, 26, 8, 3, 27, 28, 15, 7, 2, 29, 6, 30, 15, 8, 3, 2],\n",
              " [1, 5, 25, 7, 6, 26, 8, 3, 27, 28, 15, 7, 2, 29, 6, 30, 15, 8, 3, 2, 31],\n",
              " [1, 5, 25, 7, 6, 26, 8, 3, 27, 28, 15, 7, 2, 29, 6, 30, 15, 8, 3, 2, 31, 6],\n",
              " [1,\n",
              "  5,\n",
              "  25,\n",
              "  7,\n",
              "  6,\n",
              "  26,\n",
              "  8,\n",
              "  3,\n",
              "  27,\n",
              "  28,\n",
              "  15,\n",
              "  7,\n",
              "  2,\n",
              "  29,\n",
              "  6,\n",
              "  30,\n",
              "  15,\n",
              "  8,\n",
              "  3,\n",
              "  2,\n",
              "  31,\n",
              "  6,\n",
              "  32],\n",
              " [1, 16],\n",
              " [1, 16, 3],\n",
              " [1, 16, 3, 2],\n",
              " [1, 16, 3, 2, 33],\n",
              " [1, 16, 3, 2, 33, 34],\n",
              " [1, 16, 3, 2, 33, 34, 35],\n",
              " [1, 16, 3, 2, 33, 34, 35, 36],\n",
              " [1, 16, 3, 2, 33, 34, 35, 36, 16],\n",
              " [1, 16, 3, 2, 33, 34, 35, 36, 16, 1],\n",
              " [1, 16, 3, 2, 33, 34, 35, 36, 16, 1, 17],\n",
              " [1, 16, 3, 2, 33, 34, 35, 36, 16, 1, 17, 3],\n",
              " [1, 16, 3, 2, 33, 34, 35, 36, 16, 1, 17, 3, 2],\n",
              " [1, 16, 3, 2, 33, 34, 35, 36, 16, 1, 17, 3, 2, 37],\n",
              " [1, 16, 3, 2, 33, 34, 35, 36, 16, 1, 17, 3, 2, 37, 38],\n",
              " [1, 16, 3, 2, 33, 34, 35, 36, 16, 1, 17, 3, 2, 37, 38, 39],\n",
              " [1, 16, 3, 2, 33, 34, 35, 36, 16, 1, 17, 3, 2, 37, 38, 39, 17],\n",
              " [1, 16, 3, 2, 33, 34, 35, 36, 16, 1, 17, 3, 2, 37, 38, 39, 17, 1],\n",
              " [1, 16, 3, 2, 33, 34, 35, 36, 16, 1, 17, 3, 2, 37, 38, 39, 17, 1, 18],\n",
              " [1, 16, 3, 2, 33, 34, 35, 36, 16, 1, 17, 3, 2, 37, 38, 39, 17, 1, 18, 3],\n",
              " [1, 16, 3, 2, 33, 34, 35, 36, 16, 1, 17, 3, 2, 37, 38, 39, 17, 1, 18, 3, 2],\n",
              " [40, 18],\n",
              " [40, 18, 1],\n",
              " [40, 18, 1, 41],\n",
              " [40, 18, 1, 41, 3],\n",
              " [40, 18, 1, 41, 3, 2],\n",
              " [40, 18, 1, 41, 3, 2, 42],\n",
              " [40, 18, 1, 41, 3, 2, 42, 43],\n",
              " [40, 18, 1, 41, 3, 2, 42, 43, 44],\n",
              " [40, 18, 1, 41, 3, 2, 42, 43, 44, 1],\n",
              " [40, 18, 1, 41, 3, 2, 42, 43, 44, 1, 45],\n",
              " [40, 18, 1, 41, 3, 2, 42, 43, 44, 1, 45, 46],\n",
              " [40, 18, 1, 41, 3, 2, 42, 43, 44, 1, 45, 46, 2],\n",
              " [40, 18, 1, 41, 3, 2, 42, 43, 44, 1, 45, 46, 2, 47],\n",
              " [40, 18, 1, 41, 3, 2, 42, 43, 44, 1, 45, 46, 2, 47, 48]]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "max_len = max([len(x) for x in input_sequences])"
      ],
      "metadata": {
        "id": "d_B1PrvCLkS0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(max_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gp46_KxoK9gL",
        "outputId": "848848ee-12e4-411f-b350-b45fc60bd2b6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "padded_input_sequences = pad_sequences(input_sequences,maxlen = max_len,padding = 'pre')"
      ],
      "metadata": {
        "id": "y-Mqq2xensS6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_input_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXVCpKBgoWLw",
        "outputId": "2138784f-c61e-44f0-a9b9-5caac66e56ea"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0, ...,  0, 19,  1],\n",
              "       [ 0,  0,  0, ...,  0,  9,  2],\n",
              "       [ 0,  0,  0, ...,  9,  2,  4],\n",
              "       ...,\n",
              "       [ 0,  0,  0, ..., 45, 46,  2],\n",
              "       [ 0,  0,  0, ..., 46,  2, 47],\n",
              "       [ 0,  0,  0, ...,  2, 47, 48]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = padded_input_sequences[:,:-1]\n",
        "y = padded_input_sequences[:,-1]"
      ],
      "metadata": {
        "id": "BKyBKIQVouhO"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8H-ydRPqo3P",
        "outputId": "5bc00d3a-4e25-41d4-d46e-4ce2d2178727"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(89, 22)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhmDjYbuqr6E",
        "outputId": "fb48ffb0-5275-4b7e-ce73-3910012e5d2c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(89,)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y = to_categorical(y,num_classes = 49)\n",
        "#num_classes  =  unique_word + 1"
      ],
      "metadata": {
        "id": "3-986IVuqtYq"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PehMMx8OuOiv",
        "outputId": "b660df0f-21ee-4fd2-efca-a81db2f724a5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(89, 49)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding,LSTM,Dense"
      ],
      "metadata": {
        "id": "YJw_lEr7uSnU"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(49, 100, input_length=22))\n",
        "model.add(LSTM(150))\n",
        "\n",
        "model.add(Dense(49, activation='softmax'))\n",
        "#number of unique word = 48\n",
        "#maxlength = 56"
      ],
      "metadata": {
        "id": "qPJEgPfZu5hu"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam',metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "jNCAJ-8Nxh0T"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pR7ZSTumyBmY",
        "outputId": "a5f0c01d-3284-41e2-d534-75155bc49505"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 22, 100)           4900      \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 150)               150600    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 49)                7399      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 162899 (636.32 KB)\n",
            "Trainable params: 162899 (636.32 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X,y,epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdsN48DoyE2E",
        "outputId": "19fb2ce1-f504-40bb-bfea-45aa06dffaa4"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "3/3 [==============================] - 4s 247ms/step - loss: 3.8881 - accuracy: 0.0225\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 1s 255ms/step - loss: 3.8548 - accuracy: 0.1236\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 3.7947 - accuracy: 0.1236\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 0s 125ms/step - loss: 3.6386 - accuracy: 0.1236\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 0s 127ms/step - loss: 3.5131 - accuracy: 0.1236\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 3.4693 - accuracy: 0.1236\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 3.4300 - accuracy: 0.1124\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - 0s 88ms/step - loss: 3.4206 - accuracy: 0.1124\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.3999 - accuracy: 0.1461\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.3742 - accuracy: 0.1348\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 3.3631 - accuracy: 0.1236\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.3475 - accuracy: 0.1236\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.3297 - accuracy: 0.1573\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.3116 - accuracy: 0.1910\n",
            "Epoch 15/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.2752 - accuracy: 0.2022\n",
            "Epoch 16/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.2398 - accuracy: 0.2022\n",
            "Epoch 17/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 3.2075 - accuracy: 0.1798\n",
            "Epoch 18/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.1639 - accuracy: 0.1798\n",
            "Epoch 19/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.1074 - accuracy: 0.1798\n",
            "Epoch 20/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.0809 - accuracy: 0.2247\n",
            "Epoch 21/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.0232 - accuracy: 0.2247\n",
            "Epoch 22/100\n",
            "3/3 [==============================] - 0s 80ms/step - loss: 2.9437 - accuracy: 0.2247\n",
            "Epoch 23/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.9216 - accuracy: 0.2472\n",
            "Epoch 24/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.8099 - accuracy: 0.2697\n",
            "Epoch 25/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.7683 - accuracy: 0.2809\n",
            "Epoch 26/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.7055 - accuracy: 0.2809\n",
            "Epoch 27/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.6770 - accuracy: 0.2584\n",
            "Epoch 28/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.5782 - accuracy: 0.2921\n",
            "Epoch 29/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.4813 - accuracy: 0.3146\n",
            "Epoch 30/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.4359 - accuracy: 0.3258\n",
            "Epoch 31/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.3406 - accuracy: 0.3596\n",
            "Epoch 32/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.2650 - accuracy: 0.3820\n",
            "Epoch 33/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.1874 - accuracy: 0.4270\n",
            "Epoch 34/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.1048 - accuracy: 0.4607\n",
            "Epoch 35/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.0217 - accuracy: 0.4607\n",
            "Epoch 36/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 1.9623 - accuracy: 0.5281\n",
            "Epoch 37/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 1.8780 - accuracy: 0.5281\n",
            "Epoch 38/100\n",
            "3/3 [==============================] - 0s 81ms/step - loss: 1.8120 - accuracy: 0.5843\n",
            "Epoch 39/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 1.7294 - accuracy: 0.5955\n",
            "Epoch 40/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 1.6741 - accuracy: 0.5955\n",
            "Epoch 41/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 1.5874 - accuracy: 0.6629\n",
            "Epoch 42/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.5211 - accuracy: 0.6629\n",
            "Epoch 43/100\n",
            "3/3 [==============================] - 0s 80ms/step - loss: 1.4677 - accuracy: 0.6629\n",
            "Epoch 44/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 1.4161 - accuracy: 0.6292\n",
            "Epoch 45/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 1.3479 - accuracy: 0.7079\n",
            "Epoch 46/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 1.2907 - accuracy: 0.7640\n",
            "Epoch 47/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 1.2385 - accuracy: 0.7640\n",
            "Epoch 48/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 1.1750 - accuracy: 0.7753\n",
            "Epoch 49/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 1.1277 - accuracy: 0.7865\n",
            "Epoch 50/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 1.0828 - accuracy: 0.8202\n",
            "Epoch 51/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 1.0384 - accuracy: 0.8090\n",
            "Epoch 52/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.9946 - accuracy: 0.8202\n",
            "Epoch 53/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.9501 - accuracy: 0.8427\n",
            "Epoch 54/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.9238 - accuracy: 0.8539\n",
            "Epoch 55/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.8981 - accuracy: 0.8315\n",
            "Epoch 56/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.8529 - accuracy: 0.8315\n",
            "Epoch 57/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.8443 - accuracy: 0.8652\n",
            "Epoch 58/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.7848 - accuracy: 0.8652\n",
            "Epoch 59/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.7644 - accuracy: 0.8652\n",
            "Epoch 60/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.7288 - accuracy: 0.8764\n",
            "Epoch 61/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.7032 - accuracy: 0.9101\n",
            "Epoch 62/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.6786 - accuracy: 0.9101\n",
            "Epoch 63/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.6503 - accuracy: 0.9101\n",
            "Epoch 64/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.6319 - accuracy: 0.9101\n",
            "Epoch 65/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.6119 - accuracy: 0.9213\n",
            "Epoch 66/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.5988 - accuracy: 0.8989\n",
            "Epoch 67/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.5819 - accuracy: 0.9326\n",
            "Epoch 68/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.5664 - accuracy: 0.9213\n",
            "Epoch 69/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.5471 - accuracy: 0.9213\n",
            "Epoch 70/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.5235 - accuracy: 0.9326\n",
            "Epoch 71/100\n",
            "3/3 [==============================] - 0s 84ms/step - loss: 0.5049 - accuracy: 0.9438\n",
            "Epoch 72/100\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.4879 - accuracy: 0.9438\n",
            "Epoch 73/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.4784 - accuracy: 0.9438\n",
            "Epoch 74/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.4615 - accuracy: 0.9213\n",
            "Epoch 75/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.4485 - accuracy: 0.9438\n",
            "Epoch 76/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.4336 - accuracy: 0.9438\n",
            "Epoch 77/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.4235 - accuracy: 0.9438\n",
            "Epoch 78/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.9438\n",
            "Epoch 79/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.4044 - accuracy: 0.9326\n",
            "Epoch 80/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3878 - accuracy: 0.9326\n",
            "Epoch 81/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3815 - accuracy: 0.9438\n",
            "Epoch 82/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3676 - accuracy: 0.9438\n",
            "Epoch 83/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3611 - accuracy: 0.9326\n",
            "Epoch 84/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3509 - accuracy: 0.9438\n",
            "Epoch 85/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.3431 - accuracy: 0.9326\n",
            "Epoch 86/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3345 - accuracy: 0.9438\n",
            "Epoch 87/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3284 - accuracy: 0.9438\n",
            "Epoch 88/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3202 - accuracy: 0.9326\n",
            "Epoch 89/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3132 - accuracy: 0.9438\n",
            "Epoch 90/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.3030 - accuracy: 0.9438\n",
            "Epoch 91/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2983 - accuracy: 0.9438\n",
            "Epoch 92/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2947 - accuracy: 0.9438\n",
            "Epoch 93/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2920 - accuracy: 0.9213\n",
            "Epoch 94/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2882 - accuracy: 0.9213\n",
            "Epoch 95/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2781 - accuracy: 0.9438\n",
            "Epoch 96/100\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.2820 - accuracy: 0.9438\n",
            "Epoch 97/100\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.2719 - accuracy: 0.9438\n",
            "Epoch 98/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2713 - accuracy: 0.9326\n",
            "Epoch 99/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2599 - accuracy: 0.9438\n",
            "Epoch 100/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2543 - accuracy: 0.9438\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b4a70148b20>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "text = \"name of his twin brother is\"\n",
        "\n",
        "for i in range(10):\n",
        "  # tokenize\n",
        "  token_text = tokenizer.texts_to_sequences([text])[0]\n",
        "  # padding\n",
        "  padded_token_text = pad_sequences([token_text], maxlen=22, padding='pre')\n",
        "  # predict\n",
        "  pos = np.argmax(model.predict(padded_token_text))\n",
        "\n",
        "  for word,index in tokenizer.word_index.items():\n",
        "    if index == pos:\n",
        "      text = text + \" \" + word\n",
        "      print(text)\n",
        "      time.sleep(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kmkFHuh2UFG",
        "outputId": "85a41cc7-cacc-423a-e744-f4cc6176d1cc"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 344ms/step\n",
            "name of his twin brother is and\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "name of his twin brother is and sister\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "name of his twin brother is and sister shiblu\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "name of his twin brother is and sister shiblu has\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "name of his twin brother is and sister shiblu has brother\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "name of his twin brother is and sister shiblu has brother brother\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "name of his twin brother is and sister shiblu has brother brother is\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "name of his twin brother is and sister shiblu has brother brother is soumya\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "name of his twin brother is and sister shiblu has brother brother is soumya and\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "name of his twin brother is and sister shiblu has brother brother is soumya and and\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DzticBgAXgZe"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNolv78USazyrgrJTus4agS",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}